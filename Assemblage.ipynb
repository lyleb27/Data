{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemblage liste de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajout d'un colonne & Fusion des fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossier = \"CSV\"\n",
    "fichiers_a_inclure = [\"annapurna-I.csv\", \"broad-peak.csv\", \"cho-oyu.csv\", \"dhaulagiri-I.csv\", \"everest.csv\", \"gasherbrum-I.csv\", \"gasherbrum-II.csv\", \"k2.csv\", \"kangchenjunga.csv\", \"lhotse.csv\", \"makalu.csv\", \"manaslu.csv\", \"nanga-parbat.csv\", \"shishapangma.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Annapurna-I',\n",
       " 'Broad-peak',\n",
       " 'Cho-oyu',\n",
       " 'Dhaulagiri-I',\n",
       " 'Everest',\n",
       " 'Gasherbrum-I',\n",
       " 'Gasherbrum-II',\n",
       " 'K2',\n",
       " 'Kangchenjunga',\n",
       " 'Lhotse',\n",
       " 'Makalu',\n",
       " 'Manaslu',\n",
       " 'Mountain_ranges',\n",
       " 'Nanga-parbat',\n",
       " 'Shishapangma']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test a enlever\n",
    "noms_fichiers_formatés = []\n",
    "\n",
    "for fichier in os.listdir(dossier):\n",
    "    if fichier.endswith(\".csv\"):\n",
    "        # Suppression de l'extension\n",
    "        nom_sans_extension = fichier.replace('.csv', '')\n",
    "        # Rajout d'une majuscule au début du nom\n",
    "        nom_formaté = nom_sans_extension[0].upper() + nom_sans_extension[1:]\n",
    "        noms_fichiers_formatés.append(nom_formaté)\n",
    "noms_fichiers_formatés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees_totales = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fichier in fichiers_a_inclure:\n",
    "    chemin_fichier = os.path.join(dossier, fichier)\n",
    "    # Lecture du fichier CSV\n",
    "    df = pd.read_csv(chemin_fichier)\n",
    "    # Ajout de la colonne \"file\" avec le nom du fichier (sans extension .csv)\n",
    "    nom_sans_extension = fichier.replace('.csv', '')\n",
    "    df['Montagne'] = nom_sans_extension[0].upper() + nom_sans_extension[1:]\n",
    "    # Ajout du DataFrame à la liste\n",
    "    donnees_totales.append(df)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténation de tous les DataFrames en un seul\n",
    "donnees_combinees = pd.concat(donnees_totales, ignore_index=True)\n",
    "# Enregistrement des données combinées dans un fichier CSV\n",
    "donnees_combinees.to_csv('Donnees_Combinees.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Déplacement de colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le fichier CSV d'entrée et de sortie\n",
    "chemin_fichier_entree = \"Donnees_Combinees.csv\"\n",
    "chemin_fichier_sortie = \"Donnees_Combinees.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier CSV avec pandas\n",
    "donnees = pd.read_csv(chemin_fichier_entree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réorganiser les colonnes, en mettant 'Montagne' devant 'Date'\n",
    "colonnes = ['Montagne', 'Date', 'Name', 'Nationality', 'Cause of death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réorganiser les colonnes du DataFrame\n",
    "donnees = donnees[colonnes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrire le DataFrame modifié dans un nouveau fichier CSV\n",
    "donnees.to_csv(chemin_fichier_sortie, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netoyage des donné génante et inutile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le fichier CSV d'entrée et de sortie\n",
    "chemin_fichier_entree = \"Donnees_Combinees.csv\"\n",
    "chemin_fichier_sortie = \"Donnees_Combinees.csv\"\n",
    "\n",
    "# Lire le fichier CSV avec pandas\n",
    "donnees = pd.read_csv(chemin_fichier_entree)\n",
    "\n",
    "# Appliquer une expression régulière pour enlever le contenu entre crochets `[ ]` en tenant compte de l'espace éventuel avant `[`\n",
    "donnees = donnees.replace(to_replace=r'(\\s*)\\[(.*?)\\]', value='', regex=True)\n",
    "\n",
    "# Écrire le DataFrame modifié dans un nouveau fichier CSV\n",
    "donnees.to_csv(chemin_fichier_sortie, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date changement de format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour convertir la date en format jour/mois/année en nombre\n",
    "def convertir_date(date_str):\n",
    "    # Liste des formats possibles de date\n",
    "    formats = ['%d %B %Y', '%B %d, %Y', '%Y, %dth %B', '%B %Y', '%Y']\n",
    "\n",
    "    # Essayer de convertir la date avec différents formats\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            date_obj = datetime.strptime(date_str, fmt)\n",
    "            # Si la date ne contient pas de jour, retourner seulement le mois et l'année\n",
    "            if '%d' not in fmt:\n",
    "                return date_obj.strftime('%m/%Y')\n",
    "            else:\n",
    "                return date_obj.strftime('%d/%m/%Y')\n",
    "        except ValueError:\n",
    "            pass\n",
    "    # Si aucun format ne correspond, retourner la date telle quelle\n",
    "    return date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateparser\n",
    "\n",
    "def convertir_date(date_str):\n",
    "    # Essayer de parser la date avec dateparser\n",
    "    parsed_date = dateparser.parse(date_str, languages=['en'])\n",
    "    if parsed_date:\n",
    "        # Si la date n'inclut pas de jour précis, retourner seulement le mois et l'année\n",
    "        if parsed_date.day == 1:\n",
    "            return parsed_date.strftime('%m/%Y')\n",
    "        else:\n",
    "            return parsed_date.strftime('%d/%m/%Y')\n",
    "\n",
    "    # Si la date ne peut pas être analysée, retourner la date telle quelle\n",
    "    return date_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le fichier CSV d'entrée et de sortie\n",
    "chemin_fichier_entree = \"Donnees_Combinees.csv\"\n",
    "chemin_fichier_sortie = \"Donnees_Modifiees.csv\"\n",
    "\n",
    "# Lire le fichier CSV avec pandas\n",
    "donnees = pd.read_csv(chemin_fichier_entree)\n",
    "\n",
    "donnees['Date'] = donnees['Date'].replace(to_replace=\"Summer 1990\", value=\"07/1990\")\n",
    "donnees['Date'] = donnees['Date'].replace(to_replace=\"Winter 1999\", value=\"01/1999\")\n",
    "donnees['Date'] = donnees['Date'].replace(to_replace=\"mid July 1982\", value=\"15/07/1982\")\n",
    "donnees['Date'] = donnees['Date'].replace(to_replace=\"late June 1975\", value=\"28/06/1975\")\n",
    "donnees['Date'] = donnees['Date'].replace(to_replace=\"19 May 1996 or May 1997\", value=\"19/05/1996\")\n",
    "\n",
    "# Appliquer la fonction de conversion sur la colonne 'Date'\n",
    "donnees['Date'] = donnees['Date'].apply(convertir_date)\n",
    "\n",
    "# Réorganiser les colonnes, en mettant 'Montagne' devant 'Date'\n",
    "colonnes = ['Montagne', 'Date', 'Name', 'Nationality', 'Cause of death']\n",
    "\n",
    "# Réorganiser les colonnes du DataFrame\n",
    "donnees = donnees[colonnes]\n",
    "\n",
    "# Écrire le DataFrame modifié dans un nouveau fichier CSV\n",
    "donnees.to_csv(chemin_fichier_sortie, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
